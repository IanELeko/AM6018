{"name":"Better BibTeX","data":[{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":2,"entry":"@article{flynnMultifunctionalityReservoirComputer2021,\n  title = {Multifunctionality in a Reservoir Computer},\n  author = {Flynn, Andrew and Tsachouridis, Vassilios A. and Amann, Andreas},\n  year = {2021},\n  month = jan,\n  journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},\n  volume = {31},\n  number = {1},\n  pages = {013125},\n  publisher = {{American Institute of Physics}},\n  issn = {1054-1500},\n  doi = {10.1063/5.0019974},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\MX2KE9BH\\\\Flynn et al. - 2021 - Multifunctionality in a reservoir computer.pdf}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653172021695,"version":0,"updated":1653295863056},"$loki":1},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":1,"entry":"@article{flynnSymmetryKillsSquare2021,\n  title = {Symmetry Kills the Square in a Multifunctional Reservoir Computer},\n  author = {Flynn, Andrew and Herteux, Joschka and Tsachouridis, Vassilios A. and R{\\\"a}th, Christoph and Amann, Andreas},\n  year = {2021},\n  month = jul,\n  journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},\n  volume = {31},\n  number = {7},\n  pages = {073122},\n  publisher = {{American Institute of Physics}},\n  issn = {1054-1500},\n  doi = {10.1063/5.0055699},\n  abstract = {The learning capabilities of a reservoir computer (RC) can be stifled due to symmetry in its design. Including quadratic terms in the training of a RC produces a ``square readout matrix'' that breaks the symmetry to quell the influence of ``mirror-attractors,'' which are inverted copies of the RC's solutions in state space. In this paper, we prove analytically that certain symmetries in the training data forbid the square readout matrix to exist. These analytical results are explored numerically from the perspective of ``multifunctionality,'' by training the RC to specifically reconstruct a coexistence of the Lorenz attractor and its mirror-attractor. We demonstrate that the square readout matrix emerges when the position of one attractor is slightly altered, even if there are overlapping regions between the attractors or if there is a second pair of attractors. We also find that at large spectral radius values of the RC's internal connections, the square readout matrix reappears prior to the RC crossing the edge of chaos.},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\97K6PU5V\\\\Flynn et al. - 2021 - Symmetry kills the square in a multifunctional res.pdf}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653172021751,"version":0,"updated":1653295863056},"$loki":2},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":47,"entry":"@misc{teamKerasDocumentationConv1D,\n  title = {Keras Documentation: {{Conv1D}} Layer},\n  shorttitle = {Keras Documentation},\n  author = {Team, Keras},\n  abstract = {Keras documentation},\n  howpublished = {https://keras.io/api/layers/convolution\\_layers/convolution1d/},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\WPE75EQK\\\\convolution1d.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653172021876,"version":0,"updated":1653295863056},"$loki":4},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":49,"entry":"@misc{FigureSimpleScheme,\n  title = {Figure 2. (a) {{Simple}} Scheme of a One-Dimension ({{1D}}) Convolutional...},\n  journal = {ResearchGate},\n  abstract = {Download scientific diagram | (a) Simple scheme of a one-dimension (1D) convolutional operation. (b) Full representation of a 1D convolutional neural network for a SNP-matrix. The convolution outputs are represented in yellow. Pooling layers after convolutional operations combining the output of the previous layer at certain locations into a single neuron are represented in green. The final output is a standard MLP. from publication: A Guide for Using Deep Learning for Complex Trait Genomic Prediction | Deep learning (DL) has emerged as a powerful tool to make accurate predictions from complex data such as image, text, or video. However, its ability to predict phenotypic values from molecular data is less well studied. Here, we describe the theoretical foundations of DL and... | Deep Learning, Machine Learning and Multilayer Perceptron | ResearchGate, the professional network for scientists.},\n  howpublished = {https://www.researchgate.net/figure/a-Simple-scheme-of-a-one-dimension-1D-convolutional-operation-b-Full\\_fig2\\_334609713},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\XNN8YXWZ\\\\a-Simple-scheme-of-a-one-dimension-1D-convolutional-operation-b-Full_fig2_334609713.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653173541928,"version":0,"updated":1653295863056},"$loki":6},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":51,"entry":"@misc{teamKerasDocumentationConv2D,\n  title = {Keras Documentation: {{Conv2D}} Layer},\n  shorttitle = {Keras Documentation},\n  author = {Team, Keras},\n  abstract = {Keras documentation},\n  howpublished = {https://keras.io/api/layers/convolution\\_layers/convolution2d/},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\GRSWQAYW\\\\convolution2d.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653173766471,"version":0,"updated":1653295863056},"$loki":9},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":53,"entry":"@misc{FigureIllustrationsVanilla,\n  title = {Figure 1. {{Illustrations}} of Vanilla {{2D}} Convolution. (a) {{When}} the Input...},\n  journal = {ResearchGate},\n  abstract = {Download scientific diagram | Illustrations of vanilla 2D convolution. (a) When the input is a single h \\texttimes{} w map, each kernel is k \\texttimes{} k and the corresponding output is a 2D (h - k + 1) \\texttimes{} (w - k + 1) map. (b) When the input is c numbers h \\texttimes{} w maps, each kernel is k \\texttimes{} k \\texttimes{} c. Doing the same operation on each channel as in (a), getting c 2D maps and add them up. The outputs of two sub-graphs are 2D maps with the same size. from publication: PolSAR Image Classification with Lightweight 3D Convolutional Networks | Convolutional neural networks (CNNs) have become the state-of-the-art in optical image processing. Recently, CNNs have been used in polarimetric synthetic aperture radar (PolSAR) image classification and obtained promising results. Unlike optical images, the unique phase... | Convolution, Image Classification and Deep Learning | ResearchGate, the professional network for scientists.},\n  howpublished = {https://www.researchgate.net/figure/Illustrations-of-vanilla-2D-convolution-a-When-the-input-is-a-single-h-w-map-each\\_fig1\\_338847725},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\82YPH7Z6\\\\Illustrations-of-vanilla-2D-convolution-a-When-the-input-is-a-single-h-w-map-each_fig1_33884772.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653175484604,"version":0,"updated":1653295863056},"$loki":10},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":55,"entry":"@misc{hussaindeenKvasirDataset2020,\n  title = {Kvasir-{{Dataset}}},\n  author = {Hussaindeen, Afra},\n  year = {2020},\n  month = dec\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653205112852,"version":0,"updated":1653295863056},"$loki":12},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":45,"entry":"@inproceedings{pogorelovKVASIRMultiClassImage2017,\n  title = {{{KVASIR}}: {{A Multi-Class Image Dataset}} for {{Computer Aided Gastrointestinal Disease Detection}}},\n  shorttitle = {{{KVASIR}}},\n  booktitle = {Proceedings of the 8th {{ACM}} on {{Multimedia Systems Conference}}},\n  author = {Pogorelov, Konstantin and Randel, Kristin Ranheim and Griwodz, Carsten and Eskeland, Sigrun Losada and {de Lange}, Thomas and Johansen, Dag and Spampinato, Concetto and {Dang-Nguyen}, Duc-Tien and Lux, Mathias and Schmidt, Peter Thelin and Riegler, Michael and Halvorsen, P{\\aa}l},\n  year = {2017},\n  month = jun,\n  series = {{{MMSys}}'17},\n  pages = {164--169},\n  publisher = {{Association for Computing Machinery}},\n  address = {{New York, NY, USA}},\n  doi = {10.1145/3083187.3083212},\n  abstract = {Automatic detection of diseases by use of computers is an important, but still unexplored field of research. Such innovations may improve medical practice and refine health care systems all over the world. However, datasets containing medical images are hardly available, making reproducibility and comparison of approaches almost impossible. In this paper, we present KVASIR, a dataset containing images from inside the gastrointestinal (GI) tract. The collection of images are classified into three important anatomical landmarks and three clinically significant findings. In addition, it contains two categories of images related to endoscopic polyp removal. Sorting and annotation of the dataset is performed by medical doctors (experienced endoscopists). In this respect, KVASIR is important for research on both single- and multi-disease computer aided detection. By providing it, we invite and enable multimedia researcher into the medical domain of detection and retrieval.},\n  isbn = {978-1-4503-5002-0},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\428PCCIT\\\\Pogorelov et al. - 2017 - KVASIR A Multi-Class Image Dataset for Computer A.pdf}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653205112999,"version":0,"updated":1653295863056},"$loki":13},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":56,"entry":"@misc{teamKerasDocumentationBatchNormalization,\n  title = {Keras Documentation: {{BatchNormalization}} Layer},\n  shorttitle = {Keras Documentation},\n  author = {Team, Keras},\n  abstract = {Keras documentation},\n  howpublished = {https://keras.io/api/layers/normalization\\_layers/batch\\_normalization/},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\EB84X9UC\\\\batch_normalization.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653205140976,"version":0,"updated":1653295863056},"$loki":17},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":58,"entry":"@misc{teamKerasDocumentationMaxPooling2D,\n  title = {Keras Documentation: {{MaxPooling2D}} Layer},\n  shorttitle = {Keras Documentation},\n  author = {Team, Keras},\n  abstract = {Keras documentation},\n  howpublished = {https://keras.io/api/layers/pooling\\_layers/max\\_pooling2d/},\n  langid = {english},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\V9YJYK78\\\\max_pooling2d.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653205140977,"version":0,"updated":1653295863056},"$loki":18},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":60,"entry":"@misc{liuConvNet2020s2022,\n  title = {A {{ConvNet}} for the 2020s},\n  author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},\n  year = {2022},\n  month = mar,\n  number = {arXiv:2201.03545},\n  eprint = {2201.03545},\n  eprinttype = {arxiv},\n  primaryclass = {cs},\n  institution = {{arXiv}},\n  abstract = {The \"Roaring 20s\" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually \"modernize\" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8\\% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.},\n  archiveprefix = {arXiv},\n  keywords = {Computer Science - Computer Vision and Pattern Recognition},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\FBS44T7J\\\\Liu et al. - 2022 - A ConvNet for the 2020s.pdf;C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\8RW9FHLJ\\\\2201.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653208023691,"version":0,"updated":1653295863056},"$loki":20},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":65,"entry":"@misc{outcastAnswerHowGet2018,\n  title = {Answer to \"{{How}} to Get Reproducible Results in Keras\"},\n  author = {Outcast},\n  year = {2018},\n  month = oct,\n  journal = {Stack Overflow},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\3BI3449S\\\\how-to-get-reproducible-results-in-keras.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653208199262,"version":0,"updated":1653295863056},"$loki":28},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":64,"entry":"@misc{surmenokHowGetReproducible2015,\n  type = {Forum Post},\n  title = {How to Get Reproducible Results in Keras},\n  author = {Surmenok, Pavel},\n  year = {2015},\n  month = sep,\n  journal = {Stack Overflow},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\QPHYGXXV\\\\how-to-get-reproducible-results-in-keras.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":1,"created":1653208199341,"version":0,"updated":1653295863056},"$loki":29},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":66,"entry":"@misc{uraAnswerHowGet2020,\n  title = {Answer to \"{{How}} to Get Reproducible Results in Keras\"},\n  author = {Ura, Aaditya},\n  year = {2020},\n  month = jun,\n  journal = {Stack Overflow},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\W2JLXPPT\\\\how-to-get-reproducible-results-in-keras.html}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653208199363,"version":0,"updated":1653295863056},"$loki":30},{"exportNotes":false,"useJournalAbbreviation":false,"asciiBibTeX":true,"bibtexParticleNoOp":false,"bibtexURL":"off","DOIandURL":"both","itemID":70,"entry":"@article{luAttractorReconstructionMachine2018,\n  title = {Attractor Reconstruction by Machine Learning},\n  author = {Lu, Zhixin and Hunt, Brian R. and Ott, Edward},\n  year = {2018},\n  month = jun,\n  journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},\n  volume = {28},\n  number = {6},\n  pages = {061104},\n  publisher = {{American Institute of Physics}},\n  issn = {1054-1500},\n  doi = {10.1063/1.5039508},\n  file = {C\\:\\\\Users\\\\lekoi\\\\Documents\\\\AM6018\\\\Zotero\\\\storage\\\\LCPH2F9P\\\\Lu et al. - 2018 - Attractor reconstruction by machine learning.pdf}\n}\n\n","metadata":{"DeclarePrefChars":"","noopsort":false,"packages":[]},"meta":{"revision":0,"created":1653295857190,"version":0,"updated":1653295863056},"$loki":33}],"idIndex":null,"binaryIndices":{"itemID":{"name":"itemID","dirty":true,"values":[1,0,7,2,3,4,5,6,8,9,10,12,11,13,14]},"exportNotes":{"name":"exportNotes","dirty":true,"values":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]},"useJournalAbbreviation":{"name":"useJournalAbbreviation","dirty":true,"values":[]},"asciiBibTeX":{"name":"asciiBibTeX","dirty":true,"values":[]},"bibtexParticleNoOp":{"name":"bibtexParticleNoOp","dirty":true,"values":[]},"bibtexURL":{"name":"bibtexURL","dirty":true,"values":[]},"DOIandURL":{"name":"DOIandURL","dirty":true,"values":[]}},"constraints":null,"uniqueNames":[],"transforms":{},"objType":"Better BibTeX","dirty":true,"cachedIndex":null,"cachedBinaryIndex":null,"cachedData":null,"adaptiveBinaryIndices":false,"transactional":false,"cloneObjects":true,"cloneMethod":"parse-stringify","asyncListeners":false,"disableMeta":false,"disableChangesApi":true,"disableDeltaChangesApi":true,"autoupdate":false,"serializableIndices":true,"disableFreeze":true,"ttl":null,"maxId":35,"DynamicViews":[],"events":{"insert":[],"update":[],"pre-insert":[],"pre-update":[],"close":[],"flushbuffer":[],"error":[],"delete":[null],"warning":[null]},"changes":[],"dirtyIds":[]}